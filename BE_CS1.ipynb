{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9de95f5",
   "metadata": {},
   "source": [
    "# Identification des utilisateurs de Copilote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a3bf7",
   "metadata": {},
   "source": [
    "**MOD 7.2 (Introduction à la sciences des données)**, BE séances 1, 2, 3\n",
    "\n",
    "**Enseignants :** Julien Velcin (CM, BE), Erwan Versmée (BE)\n",
    "\n",
    "Le projet qu'on vous demande de réaliser concerne le traitement de **traces d'utilisation** du logiciel Copilote. Ce logiciel édité par la société Infologic, concerne le secteur de l'agro-alimentaire et est utilisé par de nombreux acteurs industriels.\n",
    "\n",
    "L'étude de ces traces est très important pour l'entreprise. Elle permet entre autre d'améliorer son offre auprès de ses clients. Le projet vous propose de travailler sur des **modèles d'analyse automatique** de ces traces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb92ce",
   "metadata": {},
   "source": [
    "## Consignes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490dc92",
   "metadata": {},
   "source": [
    "### Délimitation du travail\n",
    "\n",
    "Pour ce projet, vous travaillerez par groupe de 3 élèves. Des groupes plus petits peuvent être autorisés même s'ils ne sont pas conseillés.\n",
    "\n",
    "Les 3 séances doivent vous permettre d'avancer dans la résolution du problème qui est présenté sur la [page Kaggle de la compétition](https://www.kaggle.com/competitions/qui-utilise-mon-appli-challenge/). Elles seront grosso modo organisées de la manière suivante :\n",
    "\n",
    "1. Découverte des données, construction des variables, mise en forme tabulaire, nettoyage, premières explorations et visualisations\n",
    "2. Explorations plus avancées des données, développement d'un premier modèle de classification automatique\n",
    "3. Optimisation de votre solution de classification automatique, participation au challenge\n",
    "\n",
    "A l'issue de ces trois séances, vous aurez un peu plus d'une semaine supplémentaire pour compléter ce travail.\n",
    "\n",
    "Date limite de rendu : **2/11/25 au soir**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1dbf3c",
   "metadata": {},
   "source": [
    "### Ce qui est attendu\n",
    "\n",
    "Le rendu consiste en 3 éléments :\n",
    "\n",
    "- le *code Python* de votre solution, code qui doit être ré-exécutable dans un autre environnement (à priori, python en version 3.13). N'oubliez pas de fournir également les bibliothèques nécessaires par ex. via un fichier *requirements.txt*\n",
    "- un *rapport* au format PDF de 5 à 8 pages qui doit présenter succinctement votre travail, les choix que vous avez faits et leurs motivations, les résultats obtenus.\n",
    "- le *dépôt* de vos prédictions sur l'ensemble de test du challenge.\n",
    "\n",
    "Le **rapport** doit être déposé sur la page moodle de l'enseignement. Il doit être au format PDF et faire entre 5 et 8 pages. Il présente le problème que vous attaquez et comment vous proposez d'y répondre. Il faut en particulier présenter les différentes caractéristiques choisies, si nécessaire avec une petite explication, et les approches de classification mises en oeuvre. Il faut bien sûr présenter les résultats obtenus, en précisant bien les métriques employées, identifier si possible les variables les plus influentes, mener une petite discussion, avant de conclure.\n",
    "\n",
    "Le **code** doit être suffisamment bien structuré et commenté pour qu'un observateur en comprenne rapidement le fonctionnement, y compris à la lumière du rapport. N'hésitez pas à le rendre disponible sur une plateforme de type git (avec le fichier README adapté) et de fournir l'url directement dans le rapport. Sinon, vous pouvez aussi fournir le code dans une archive (ZIP, TAR...) et le déposer en même temps que votre rapport, mais *sans* y mettre les fichiers de données.\n",
    "\n",
    "Il est possible de rendre un notebook *à condition* que celui-ci soit succinct et très lisible (ce qui ne veut pas dire que le code intégral soit, lui, succinct).\n",
    "\n",
    "Le **dépôt** doit être réalisé sur le page du leaderboard de la compétition :\n",
    "\n",
    "- Groupe TD - 1 (8h-10h), Julien Velcin : https://www.kaggle.com/t/077eb1959d124b11971668f381767f06\n",
    "- Groupe TD - 2 (8h-10h), Erwan Versmée :  https://www.kaggle.com/t/2374f58cda734c69a28a8ba3ef6692e8\n",
    "- Groupe TD - 3 (10h-12h),  Julien Velcin :  https://www.kaggle.com/t/ce3349734cc44028bad2875d462e7085\n",
    "- Groupe TD - 4 (10h-12h), Erwan Versmée :  https://www.kaggle.com/t/6435d33bed324430a9749337b04c2168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6323ebc",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "L'évaluation de ce travail sera réalisée selon trois critères :\n",
    "\n",
    "- mise en place d'une chaîne de traitement complète d'analyse\n",
    "- capacité à expliquer et motiver les différents traitement mis en oeuvre\n",
    "- production d'une solution efficace dans un contexte concurrentiel\n",
    "\n",
    "En plus d'une note /20, vous serez également évalué lors de la 3ème séance de BE selon la compétence C2C2 **Résoudre et arbitrer** :\n",
    "\n",
    "- *A (remarquable si)* : identifie les méthodes les plus pertinentes pour répondre au problème imposé, exploite la méthode choisie pour répondre au problème, choisit des critères pertinents pour évaluer l'efficacité.\n",
    "- *C (acquis si)* : identifie les méthodes les plus pertinentes pour répondre au problème imposé, exploite la méthode choisie pour répondre au problème.\n",
    "- *F (à travailler si)* : n'identifie pas les méthodes les plus pertinentes pour répondre au problème imposé, et/ou propose une exploitation de la méthode choisie qui ne répond pas suffisamment au problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c84e42",
   "metadata": {},
   "source": [
    "## Résolution du problème\n",
    "\n",
    "Nous vous proposons de suivre les étapes suivantes dans le traitement de cette problématique :\n",
    "\n",
    "- Prendre connaissance du problème et des données à votre disposition\n",
    "- Chargement des données brutes en mémoire\n",
    "- Première analyse de ces données\n",
    "- Construction de caractéristiques adaptées\n",
    "- Statistiques simples sur les variables construites\n",
    "- Développement d'une solution de classification automatique\n",
    "- Evaluation de votre solution\n",
    "- Discussion au sujet de vos résultats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7849a",
   "metadata": {},
   "source": [
    "## Prendre connaissance du problème et des données à votre disposition\n",
    "\n",
    "Pour commencer, allez lire la description plus détaillée du problème qui vous est donnée sur la page du challenge mis en place cette année (cf. lien ci-dessus).\n",
    "\n",
    "Les données sont présentées plus en détail et téléchargeables via l'onglet \"data\".\n",
    "\n",
    "L'objectif consiste à comprendre à quoi correspondent chacune des lignes du tableau des données et commencer à vous poser des questions sur la manière d'utiliser ces données pour répondre au challenge. Pour le moment, vous pouvez utiliser un **simple éditeur** (comme Notepad++, Sublime Text...) pour aller voir le contenu des fichiers, les importer dans Excel (mais attention car le volume peut rendre les manipulatins difficiles), ou passer déjà par Python si vous êtes suffisamment à l'aise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eded2",
   "metadata": {},
   "source": [
    "## Chargement des données brutes en mémoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b550e042",
   "metadata": {},
   "source": [
    "La toute première étape dans le traitement des données avec Python est de les charger en mémoire pour pouvoir mieux les examiner. Plusieurs solutions s'offrent alors à vous, parmi lesquelles :\n",
    "\n",
    "- utiliser la librairie Pandas et les méthodes qui permettent de charger directement les données dans des DataFrame comme *readcsv*,\n",
    "- ouvrir le fichier texte en mode lecture (*open*) et parcourir les lignes grâce à la commande *readlines()*\n",
    "\n",
    "Cette dernière approche semble plus robuste au regard de la régularité du fichier d'entrée. Identifiez le délimiteur qui permet de séparer les différentes actions de l'utilisateur et utilisez-le pour construire la liste des actions réalisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab722484",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3130 fields in line 42, saw 3259\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df.head())\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mread_ds\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# Example: call with filename relative to data/ folderread_ds(\"train.csv\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mread_ds\u001b[39m\u001b[34m(ds_name)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_ds\u001b[39m(ds_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Note: some lines have fewer columns; pandas will fill missing entries with NaN.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Replace NaN with empty string to simplify string-processing downstream\u001b[39;00m\n\u001b[32m      7\u001b[39m     df = df.fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aurel\\Projects\\centrale-4a\\introduction_data_science\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aurel\\Projects\\centrale-4a\\introduction_data_science\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aurel\\Projects\\centrale-4a\\introduction_data_science\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aurel\\Projects\\centrale-4a\\introduction_data_science\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 3130 fields in line 42, saw 3259\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def read_ds(ds_name: str):\n",
    "    \"\"\"Robust CSV loader for files where rows have variable field counts.\n",
    "    Uses Python's csv.reader to parse lines, pads rows to the maximum column count with empty strings,\n",
    "    and returns a pandas DataFrame with missing values replaced by empty strings.\n",
    "    Accepts either 'train' or 'train.csv' as input.\n",
    "    \"\"\"\n",
    "    filename = ds_name if ds_name.endswith('.csv') else ds_name + '.csv'\n",
    "    path = os.path.join('data', filename)\n",
    "    # Read using csv.reader which avoids pandas C-engine tokenization errors on malformed rows\n",
    "    with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        reader = csv.reader(f)\n",
    "        rows = [row for row in reader]\n",
    "    if not rows:\n",
    "        print(f\"No rows read from {path}\")\n",
    "        return pd.DataFrame()\n",
    "    max_cols = max(len(r) for r in rows)\n",
    "    padded = [r + [''] * (max_cols - len(r)) for r in rows]\n",
    "    df = pd.DataFrame(padded)\n",
    "    df = df.fillna('')\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# Example call (accepts with or without .csv)\n",
    "read_ds('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = read_ds(\"train\")\n",
    "features_test = read_ds(\"test\")\n",
    "features_train.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b080ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf90506",
   "metadata": {},
   "source": [
    "## Première analyse de ces données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3f4b5",
   "metadata": {},
   "source": [
    "Les données contiennent l'utilisateur (e.g. la variable dépendante, uniquement pour l'ensemble d'apprentissage), le navigateur choisi par l'utilisateur, puis toutes les actions effectuées dans la session par l'utilisateur actuel. Un marqueur spécial « tXX » indique un intervalle de temps de 5 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.loc[:,:20].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca1b51",
   "metadata": {},
   "source": [
    "La première observation des données montre que nous avons un nombre considérable de colonnes (14470), mais la plupart d'entre elles semblent contenir des valeurs NaN, ce qui est logique puisque pandas étend les lignes comportant moins de colonnes afin qu'elles aient toutes le même nombre de colonnes, ajoutant ainsi des valeurs NaN aux champs manquants. Quelques utilisateurs ont gardé la même session pendant une très longue durée, alors que la plupart ont des sessions plus courtes ou de durée moyenne. Ainsi, les quelques sessions longues ont entraîné l'extension de toutes les autres à leur durée. C'est de là que proviennent toutes ces valeurs NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac63d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspecter les valeurs distinctes des navigateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02efaa8",
   "metadata": {},
   "source": [
    "Quelques fonctions \"utilitaires\" qui pourraient vous être utiles (ou pas) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65275d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# décorateurs utilitaires pour supprimer les avertissements de la sortie et imprimer un cadre de données dans un tableau Markdown.\n",
    "def ignore_warnings(f):\n",
    "    def _f(*args, **kwargs):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        v = f(*args, **kwargs)\n",
    "        warnings.filterwarnings('default')\n",
    "        return v\n",
    "    return _f\n",
    "\n",
    "# affiche un DataFrame Pandas sous forme de tableau Markdown dans un notebook Jupyter.\n",
    "def markdown_table(headNtail=False, use_index=True, title=None, precision=2):\n",
    "    def _get_value(val): return str(round(val, precision) if isinstance(val, float) else val)\n",
    "    def _format_row(row): \n",
    "        row_str = \"\"\n",
    "        if use_index: row_str += f\"|{str(row.name)}\"\n",
    "        for value in row.values: row_str += f\"| {_get_value(value)}\"\n",
    "        return row_str + \"|\"\n",
    "    def _get_str(df):\n",
    "        return \"\\n\".join(df.apply(_format_row, axis=1))\n",
    "    def _deco(f):\n",
    "        def _f(*args, **kwargs):\n",
    "            df = f(*args, **kwargs)\n",
    "            _str = f\"#### {title}\\n\" if title else \"\"\n",
    "            header = ([str(df.index.name)] if use_index else []) + df.columns.astype(str).to_list() \n",
    "            _str += f\"|{'|'.join(header)}|\" + f\"\\n|{'--|'*len(header)}\\n\" if header else None\n",
    "            if headNtail:\n",
    "                _str += _get_str(df.head())\n",
    "                _str += \"\\n|...|...|\\n\"\n",
    "                _str += _get_str(df.tail())\n",
    "            else:\n",
    "                _str += _get_str(df)\n",
    "            display(Markdown(_str))\n",
    "        return _f\n",
    "    return _deco\n",
    "\n",
    "# fonction utilitaire permettant d'obtenir une grille graphique à partir d'un nombre arbitraire de lignes/colonnes ou de données.\n",
    "def get_grid(n, n_row=None, n_col=None, titles=None, figsize=(10, 8), wspace=.5, hspace=.5, **kwargs):\n",
    "    if n_row: n_col= n_col or math.floor(n/n_row)\n",
    "    elif n_col: n_row= n_row or math.ceil(n/n_col)\n",
    "    else:\n",
    "        n_row = math.ceil(math.sqrt(n))\n",
    "        n_col = math.floor(n/n_row)\n",
    "    fig, axs = plt.subplots(n_row, n_col, figsize=figsize, **kwargs)\n",
    "    plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "    if titles is not None:\n",
    "        for ax, title in zip(axs.flat, titles): ax.set_title(title)\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d34b2",
   "metadata": {},
   "source": [
    "Maintenant que nous avons un premier aperçu de nos données, approfondissons un peu et examinons quelques statistiques à leur sujet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@markdown_table(title=\"Navigateur par utilisateur\", headNtail=True)\n",
    "def browsers_per_player(df):\n",
    "    # Afficher ici pour chaque utilisateur (en ligne) le nombre de fois qu'il a utilisé chaque navigateur (en colonne)\n",
    "\n",
    "# TODO: inspecter d'autre statistiques du jeu de données (la variable dépendante Y sera inspecté dans la prochaine cellule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338567b",
   "metadata": {},
   "source": [
    "// Votre analyse ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@markdown_table(headNtail=True, title=\"Stats: Y distribution\")\n",
    "def get_Y_stats(df):\n",
    "    # Inspecter la distribution de la variable dépendante ici (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeedfd0",
   "metadata": {},
   "source": [
    "// Votre analyse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321155f",
   "metadata": {},
   "source": [
    "## Construction de caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d16c70",
   "metadata": {},
   "source": [
    "### Traitements préliminaires\n",
    "\n",
    "En fonction du modèle choisi, différentes étapes de pré-traitement peuvent être nécessaire. Voir https://scikit-learn.org/stable/supervised_learning.html pour des exemples de modèles dans le cas supervisé (notre cas). Quelques exemples : \n",
    "- SVMs\n",
    "- Régression logistiques\n",
    "- Arbres de décision\n",
    "- Modèle ensembliste (Random Forest, XGBoost, etc.)\n",
    "- Réseaux de neurones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342aae72",
   "metadata": {},
   "source": [
    "Il faut commencer par se demander s'il y a des valeurs aberrantes (*outliers*) et, le cas échéant, appliquer le traitement approprié (pour le moment vous pouvez à priori les supprimer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: inspecter s'il y a des valeurs aberrantes, et les enlever le cas échéant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e7bc5",
   "metadata": {},
   "source": [
    "### Variable de classe\n",
    "Notre variable dépendante est une chaîne de caractères (str). Nous pouvons la convertir en codes catégoriels (numériques) à l'aide de la fonction pd.Categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train[\"util\"] = pd.Categorical(features_train[\"util\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50e06b",
   "metadata": {},
   "source": [
    "pd.Categorical ne modifie pas directement l'ID utilisateur en un nombre, mais lui ajoute un attribut cat.codes. Nous pouvons créer une petite fonction pour convertir la variable de classe d'une chaîne de caractères en son ID de catégorie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categories(df, col=\"util\"):\n",
    "    df[[col]] = df[[col]].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c3d25",
   "metadata": {},
   "source": [
    "### Obtention des caractéristiques...\n",
    "\n",
    "Nous allons maintenant créer des caractéristiques à partir de l'ensemble de données. Pour cela, il va falloir comprendre leur format, les parser et voir comment les agréger. On peut commencer par inspecter toutes les actions différentes, indépendemment des informations sur l'écran ou la fiche travaillée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_action(value: str):\n",
    "    for delim in [ \"(\", \"<\", \"$\", \"1\"]:\n",
    "        if delim in value and (low_ind := value.index(delim)):\n",
    "            value = value[:low_ind]\n",
    "    return value\n",
    "\n",
    "uniques = features_train.iloc[:,2:].stack().unique()\n",
    "filtered_uniques = list(set([filter_action(un) for un in uniques if not un.startswith(\"t\")]))\n",
    "len(filtered_uniques), filtered_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Définir des features sur les données brutes et les placer dans un nouveau dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40808a",
   "metadata": {},
   "source": [
    "Ensuite, on peut employer des fonctions plus complexes pour extraire l'écran le plus utilisé, la configuration d'écran la plus utilisé et la chaîne (catégorie) de la fiche la plus utilisé. Pour vous aider, voici les expressions régulières (*regex*) qui permettent d'extraire de telles informations. N'hésitez pas à extraire d'autres informations si cela vous parait pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92867fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "pattern_ecran = re.compile(r\"\\((.*?)\\)\")\n",
    "pattern_conf_ecran = re.compile(r\"<(.*?)>\")\n",
    "pattern_chaine = re.compile(r\"\\$(.*?)\\$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cc960",
   "metadata": {},
   "source": [
    "### Traitement des chaînes de caractère\n",
    "La colonne navigateur ne peut prendre que quatre valeurs ; pour la convertir en nombre, on a deux choix : \n",
    "- la convertir en variable catégorielle comme nous l'avons fait avec notre variable dépendante\n",
    "- la convertir en One-Hot Encoding (OHE), un pour chaque navigateur. Pandas propose également une fonction pour cela : get_dummies\n",
    "\n",
    "En fonction du modèle, l'un ou l'autre peut être plus pertinent (par exemple, pour un arbre de décision ?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : traiter les chaînes de caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93a517",
   "metadata": {},
   "source": [
    "## Statistiques simples sur les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811c120",
   "metadata": {},
   "source": [
    "### Inspection des caractéristiques\n",
    "\n",
    "Commencez par inspecter les caractéristiques que vous avez construites, et afficher des graphiques en les interprétant. Vous pouvez utiliser la librairie Matplotlib à cette fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=True, figsize=(20,6))\n",
    "# TODO: afficher des graphiques de trois features différentes sur les trois axes donnés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb57315",
   "metadata": {},
   "source": [
    "// Votre analyse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20e22a",
   "metadata": {},
   "source": [
    "### Inspection de la corrélation d'une caractéristique pour une classe particulière\n",
    "Comme il peut être difficile d'inspecter les données lorsque nous avons un tel nombre de classes possibles, nous pouvons commencer par tracer des graphiques de corrélation pour une ou quelques cibles particulières, choisies arbitrairement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3901a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categories(categories, type_=\"box\", feature=\"actions_means\"):\n",
    "    fig, axs = get_grid(len(categories), n_row=1, figsize=(16, 4))\n",
    "    # TODO : afficher les graphiques des catégories passées en paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a001f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0, 15, 152, 199]\n",
    "plot_categories(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fdf944",
   "metadata": {},
   "source": [
    "Un boxplot est très utile pour estimer la distribution d'une caractéristique au sein d'une catégorie (cf. cours), mais d'autres visualisations peuvent servir comme les violin plots, cf. : https://www.data-to-viz.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663be13",
   "metadata": {},
   "source": [
    "// à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2ae5b",
   "metadata": {},
   "source": [
    "## Développement d'une solution de classification automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5596e",
   "metadata": {},
   "source": [
    "Une fois que vous avez exploré les données et mieux compris comment résoudre la tâche qui vous est confiée, c'est le moment de commencer à développer votre solution de classification automatique supervisée.\n",
    "\n",
    "La première opération consiste à séparer votre jeu de données en deux sous-ensembles : un jeu d'entraînement (**training set**) et un jeu de validation (**validation set**). Le jeu de validation vous aidera dans la sélection du meilleur modèle. Suivant les algorithmes employés, et leur coût computationnel, vous pourriez aussi avoir recours à la validation croisée à K-folds (*K-fold cross validation*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4580659",
   "metadata": {},
   "source": [
    "Il s'agit ensuite de tester plusieurs algorithmes classiques et de faire varier ses hyper-paramètres, tel que :\n",
    "\n",
    "- Régression logistique\n",
    "- Machines à vecteurs supports (SVM) : différents types de noyau (linéaire, polynomial à différents degrés)\n",
    "- Arbres de décisions simples\n",
    "- Ensembles d'arbres (Random Forest, XGBoost) : nombre d'arbres\n",
    "- Réseaux de neurones artificiels (simple MLP) : nombre de couches, nombre de neurones par couche\n",
    "\n",
    "Vous pouvez également tester les méthodes de régularisation afin d'obtenir des modèles parcimonieux.\n",
    "\n",
    "Pour cela, vous privilégierez l'usage de la librairie *scikit-learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376258f",
   "metadata": {},
   "source": [
    "## Evaluation de votre solution\n",
    "\n",
    "Les algorithmes déployés dans la section précédente permettent de réaliser des prédictions sur des données qui n'ont pas été vus durant l'entraînement. Dans le cadre de cette compétition, vous utiliserez pour ça un ensemble de validation.\n",
    "\n",
    "Il s'agit à présent de définir convenablement et d'utiliser les métriques les plus appropriées à votre tâche. On vous conseille à minima d'employer la **réussite simple** en classification (*accuracy*) et la **F-Mesure** (ou F1-score) mais vous êtes aussi encouragés à utiliser d'autres manière d'évaluer l'efficacité d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532605a",
   "metadata": {},
   "source": [
    "// à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19543c1",
   "metadata": {},
   "source": [
    "## Discussion au sujet de vos résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90276f69",
   "metadata": {},
   "source": [
    "Il faut discuter de vos résultats, si possible en prenant en compte tous les critères que vous jugerez utiles (cf. mesures discutées dans la partie précédente)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae9394",
   "metadata": {},
   "source": [
    "## Evaluation sur l'ensemble de données de test\n",
    "\n",
    "Il s'agit enfin d'utiliser votre modèle sur l'ensemble de données de test fourni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ddebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: preprocess test dataset, compute features values and post-process it (handle string, etc.)\n",
    "test_processed_df = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf870d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test =  votre_modele.predict(test_processed_df)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac3dbd",
   "metadata": {},
   "source": [
    "## Soumission à la compétition Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa450523",
   "metadata": {},
   "source": [
    "Il faut bien mettre en forme le fichier que vous pourrez utiliser pour soumettre sur le site de la compétitiokn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b671907",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.Categorical.from_codes(preds_test, features_train[\"util\"].cat.categories)\n",
    "df_subm = pd.DataFrame(preds_test)\n",
    "df_subm = df_subm.rename_axis('RowId')\n",
    "df_subm.rename(columns={0: 'prediction'}, inplace=True)\n",
    "df_subm.index = df_subm.index + 1\n",
    "df_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
