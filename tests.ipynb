{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43132f07",
   "metadata": {},
   "source": [
    "# Pipeline Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d8739",
   "metadata": {},
   "source": [
    "## 1. Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from model.reader import reader\n",
    "\n",
    "df = reader('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = df.iloc[:, 0]\n",
    "browser = df.iloc[:, 1]\n",
    "actions = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca33244",
   "metadata": {},
   "source": [
    "## 2. Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.parser import parse_action_string\n",
    "\n",
    "parsed_actions = actions.map(parse_action_string)\n",
    "parsed_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80064f",
   "metadata": {},
   "source": [
    "## 3. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.tokenizer import tokenize_action_sequence\n",
    "\n",
    "session_tokens, token_to_idx = tokenize_action_sequence(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa0a2b",
   "metadata": {},
   "source": [
    "## 4. Model: Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c9ad9",
   "metadata": {},
   "source": [
    "Read device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Enable memory optimization\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer import create_model, train_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create model\n",
    "vocab_size = len(token_to_idx)\n",
    "n_usernames = len(TARGET.unique())\n",
    "\n",
    "# Create optimized model for T4 GPU\n",
    "model = create_model(\n",
    "    vocab_size=vocab_size,\n",
    "    n_usernames=n_usernames,\n",
    "    d_model=128,        # Increased for better performance\n",
    "    n_heads=4,          # More attention heads\n",
    "    n_layers=4,         # Deeper network\n",
    "    d_ff=512,\n",
    "    max_seq_len=100,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3d654",
   "metadata": {},
   "source": [
    "Encode usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4735377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "unique_usernames = TARGET.unique()\n",
    "username_to_idx = {username: idx for idx, username in enumerate(unique_usernames)}\n",
    "TARGET_indices = TARGET.map(username_to_idx).values\n",
    "TARGET_tensor = torch.tensor(TARGET_indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baa8b9",
   "metadata": {},
   "source": [
    "Train Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cadb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the raw session_tokens (list of lists) instead of converting to tensor\n",
    "# This allows the training function to handle padding properly\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.8 * len(session_tokens))\n",
    "val_size = len(session_tokens) - train_size\n",
    "\n",
    "# Split session_tokens and TARGET_tensor\n",
    "train_tokens = session_tokens[:train_size]\n",
    "val_tokens = session_tokens[train_size:]\n",
    "\n",
    "train_targets = TARGET_tensor[:train_size]\n",
    "val_targets = TARGET_tensor[train_size:]\n",
    " \n",
    "# Train with memory-efficient parameters\n",
    "train_model(\n",
    "    model,\n",
    "    (train_tokens, train_targets),\n",
    "    (val_tokens, val_targets),\n",
    "    epochs=100,\n",
    "    batch_size=64,      # Larger batch size for GPU\n",
    "    max_seq_len=100,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict username from action sequence\n",
    "action_sequence = torch.tensor([5, 32, 1, 52, 89]).to(device)\n",
    "logits, probs = model.predict_username(action_sequence)\n",
    "predicted_username = torch.argmax(logits, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
