{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43132f07",
   "metadata": {},
   "source": [
    "# Pipeline Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d8739",
   "metadata": {},
   "source": [
    "## 1. Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from model.reader import reader\n",
    "\n",
    "df = reader('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = df.iloc[:, 0]\n",
    "browsers = df.iloc[:, 1]\n",
    "sequence_lengths = df.iloc[:, 2]\n",
    "actions = df.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07944e89",
   "metadata": {},
   "source": [
    "## Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.time_features import compute_time_features\n",
    "\n",
    "time_features = compute_time_features(actions, sequence_lengths)\n",
    "time_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80064f",
   "metadata": {},
   "source": [
    "## 2. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.tokenizer import tokenize_action_sequence, tokenize_browser_data, tokenize_username_data\n",
    "\n",
    "username_tokens, username_to_idx = tokenize_username_data(TARGET)\n",
    "action_tokens, action_to_idx = tokenize_action_sequence(actions)\n",
    "browser_tokens, browser_to_idx = tokenize_browser_data(browsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca69ff2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c488db2",
   "metadata": {},
   "source": [
    "### Model: kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa0a2b",
   "metadata": {},
   "source": [
    "### Model: Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c9ad9",
   "metadata": {},
   "source": [
    "Read device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Enable memory optimization\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer import create_model, train_model\n",
    "\n",
    "# Create optimized model for T4 GPU\n",
    "model = create_model(\n",
    "    vocab_size=len(action_to_idx),\n",
    "    n_usernames=len(username_to_idx),\n",
    "    n_browsers=len(browser_to_idx),\n",
    "    d_model=256,        # Increased for better performance\n",
    "    n_heads=8,          # More attention heads\n",
    "    n_layers=6,         # Deeper network\n",
    "    d_ff=512,\n",
    "    max_seq_len=100,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baa8b9",
   "metadata": {},
   "source": [
    "Train Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cadb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the raw session_tokens (list of lists) instead of converting to tensor\n",
    "# This allows the training function to handle padding properly\n",
    "\n",
    "# Split data (simple 80/20 split)\n",
    "split_idx = int(0.8 * len(df))\n",
    "train_data = (\n",
    "    action_tokens[:split_idx],\n",
    "    username_tokens[:split_idx],\n",
    "    browser_tokens[:split_idx]\n",
    ")\n",
    "val_data = (\n",
    "    action_tokens[split_idx:],\n",
    "    username_tokens[split_idx:],\n",
    "    browser_tokens[split_idx:]\n",
    ")\n",
    " \n",
    "# Train with memory-efficient parameters\n",
    "train_model(\n",
    "    model,\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    epochs=100,\n",
    "    batch_size=32,      # Larger batch size for GPU\n",
    "    max_seq_len=500,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307b5953",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_username_from_prediction(predicted_tensor, username_to_idx):\n",
    "    \"\"\"Convert predicted tensor index to actual username.\"\"\"\n",
    "    idx_to_username = {idx: username for username, idx in username_to_idx.items()}\n",
    "    predicted_idx = predicted_tensor.item()\n",
    "    return idx_to_username[predicted_idx]\n",
    "\n",
    "# Predict username from action sequence\n",
    "action_sequence = torch.tensor([5, 32, 1, 52, 89]).to(device)\n",
    "logits, probs = model.predict_username(action_sequence)\n",
    "predicted_username = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Get the actual username\n",
    "predicted_username_name = get_username_from_prediction(predicted_username, username_to_idx)\n",
    "print(f\"Predicted username: {predicted_username_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
